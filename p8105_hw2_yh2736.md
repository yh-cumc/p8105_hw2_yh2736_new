P8105 Homework2
================
Yongmei Huang
10/4/2019

# Problem 1

``` r
##upload and clean the trashwheel dataset
trashwheel_dataset = read_excel(path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                                sheet = "Mr. Trash Wheel",
                                range = cell_cols("A:N")) %>%  ## upload the xlsx file
  janitor::clean_names() %>%                                   ## clean the dataset
  na.omit()                                                    ## omit row with NULL data    

trashwheel_dataset$sports_balls = round(as.integer(trashwheel_dataset$sports_balls), 
                                        digits = 0)     ## round the sports balls to nearest inter
####checkpoints####
count(trashwheel_dataset) #344 obs#
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   344

``` r
head(trashwheel_dataset,5)
```

    ## # A tibble: 5 x 14
    ##   dumpster month  year date                weight_tons volume_cubic_ya~
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>            <dbl>
    ## 1        1 May    2014 2014-05-16 00:00:00        4.31               18
    ## 2        2 May    2014 2014-05-16 00:00:00        2.74               13
    ## 3        3 May    2014 2014-05-16 00:00:00        3.45               15
    ## 4        4 May    2014 2014-05-17 00:00:00        3.1                15
    ## 5        5 May    2014 2014-05-17 00:00:00        4.06               18
    ## # ... with 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, grocery_bags <dbl>,
    ## #   chip_bags <dbl>, sports_balls <dbl>, homes_powered <dbl>

``` r
summary(trashwheel_dataset)
```

    ##     dumpster         month                year     
    ##  Min.   :  1.00   Length:344         Min.   :2014  
    ##  1st Qu.: 86.75   Class :character   1st Qu.:2015  
    ##  Median :172.50   Mode  :character   Median :2017  
    ##  Mean   :172.50                      Mean   :2016  
    ##  3rd Qu.:258.25                      3rd Qu.:2018  
    ##  Max.   :344.00                      Max.   :2019  
    ##       date                      weight_tons    volume_cubic_yards
    ##  Min.   :2014-05-16 00:00:00   Min.   :0.960   Min.   : 7.00     
    ##  1st Qu.:2015-07-05 00:00:00   1st Qu.:2.757   1st Qu.:15.00     
    ##  Median :2017-03-31 00:00:00   Median :3.265   Median :15.00     
    ##  Mean   :2016-12-23 10:57:12   Mean   :3.263   Mean   :15.54     
    ##  3rd Qu.:2018-05-19 18:00:00   3rd Qu.:3.772   3rd Qu.:16.00     
    ##  Max.   :2019-06-17 00:00:00   Max.   :5.620   Max.   :20.00     
    ##  plastic_bottles   polystyrene   cigarette_butts  glass_bottles   
    ##  Min.   : 210.0   Min.   : 320   Min.   :   980   Min.   :  0.00  
    ##  1st Qu.: 957.5   1st Qu.:1065   1st Qu.:  7000   1st Qu.: 10.00  
    ##  Median :1835.0   Median :2075   Median : 19000   Median : 21.50  
    ##  Mean   :1873.2   Mean   :2139   Mean   : 30754   Mean   : 25.36  
    ##  3rd Qu.:2552.5   3rd Qu.:3120   3rd Qu.: 38000   3rd Qu.: 38.00  
    ##  Max.   :5960.0   Max.   :6540   Max.   :310000   Max.   :110.00  
    ##   grocery_bags    chip_bags       sports_balls   homes_powered  
    ##  Min.   :  50   Min.   : 230.0   Min.   : 0.00   Min.   : 0.00  
    ##  1st Qu.: 600   1st Qu.: 977.5   1st Qu.: 5.00   1st Qu.:35.62  
    ##  Median :1050   Median :1630.0   Median : 8.00   Median :51.42  
    ##  Mean   :1311   Mean   :1780.3   Mean   :11.79   Mean   :43.83  
    ##  3rd Qu.:1912   3rd Qu.:2490.0   3rd Qu.:16.00   3rd Qu.:59.50  
    ##  Max.   :3750   Max.   :5085.0   Max.   :56.00   Max.   :93.67

``` r
####checkend####
```

``` r
##upload and clean the precipitation data of 2017
precipitation_dataset_2017 = read_excel(path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                                        sheet = "2017 Precipitation", 
                                        range = "A2:B14") %>%  ##upload 2017 precipitation data 
  na.omit() %>%                                                  ##omit rows without precipitation data
  janitor::clean_names() %>%                                     ##clean data
  mutate(year = '2017')                                          ##add a variable year

####checkpoints####
count(precipitation_dataset_2017) #12 obs#
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    12

``` r
view(precipitation_dataset_2017)
summary(precipitation_dataset_2017)
```

    ##      month           total           year          
    ##  Min.   : 1.00   Min.   :0.000   Length:12         
    ##  1st Qu.: 3.75   1st Qu.:1.285   Class :character  
    ##  Median : 6.50   Median :2.145   Mode  :character  
    ##  Mean   : 6.50   Mean   :2.744                     
    ##  3rd Qu.: 9.25   3rd Qu.:4.103                     
    ##  Max.   :12.00   Max.   :7.090

``` r
####checkend####
```

``` r
##upload and clean the precipitation data of 2017
precipitation_dataset_2018 = read_excel(path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                                        sheet = "2018 Precipitation", 
                                        range = "A2:B14") %>%    ##upload 2018 precipitation data
  na.omit() %>%                                                  ##omit rows without precipitation data
  janitor::clean_names() %>%                                     ##clean data
  mutate(year = '2018')                ##add a variable year


####checkpoints####
count(precipitation_dataset_2018) #12 obs#
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    12

``` r
view(precipitation_dataset_2018)
summary(precipitation_dataset_2018)
```

    ##      month           total            year          
    ##  Min.   : 1.00   Min.   : 0.940   Length:12         
    ##  1st Qu.: 3.75   1st Qu.: 4.190   Class :character  
    ##  Median : 6.50   Median : 5.455   Mode  :character  
    ##  Mean   : 6.50   Mean   : 5.861                     
    ##  3rd Qu.: 9.25   3rd Qu.: 8.182                     
    ##  Max.   :12.00   Max.   :10.470

``` r
####checkend####
```

``` r
##combination the two dataset of precipitation_dataset_2017 and precipitation_dataset_2018
precipitation_dataset = left_join(
  precipitation_dataset_2017, 
  precipitation_dataset_2018, 
  by = "month",
  suffix = c("_2017", "_2018")
) %>% 
  select("month", "total_2017", "total_2018") %>% 
  rename("precipitation_2017" = "total_2017", "precipitation_2018" = "total_2018") 
precipitation_dataset$month = month.name[precipitation_dataset$month]

####checkpoints####
count(precipitation_dataset) #12 obs#
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    12

``` r
view(precipitation_dataset)
summary(precipitation_dataset)
```

    ##     month           precipitation_2017 precipitation_2018
    ##  Length:12          Min.   :0.000      Min.   : 0.940    
    ##  Class :character   1st Qu.:1.285      1st Qu.: 4.190    
    ##  Mode  :character   Median :2.145      Median : 5.455    
    ##                     Mean   :2.744      Mean   : 5.861    
    ##                     3rd Qu.:4.103      3rd Qu.: 8.182    
    ##                     Max.   :7.090      Max.   :10.470

``` r
####checkend####
```

In problem1, three datasets were used. Trash wheel includes information
of 344 dumpster from year 2014 to 2019. For each dumpster, the dataset
collects information on weight, volume, plastic bottles, polystyrene,
cigarette butts, glass bottles, grocery bags, chip bags, sports balls,
and homes powered.Each of these information is a independent varaible
that can be summaried using the commamment of summary() that is
presented in the my command line as check points. For example,the
collected sport balls range from 0 to 56 with a median of 8 and IQR
5-16. The sport ball data is right skwed for the mean (11.79) is much
bigger than the median (8).

In the original Trash Wheel Collection excel sheet, the precipitation
was collected seperately by year. In the assigment, we are requested to
upload 2017 and 2018 data, and combine these two year data. For the
convenience of data revievewing, I use the left join for the wide format
of dataset, and create seperate variables to represent the precipitation
by year in each month. The combination can also be done in long format
by stacking 2017 data on the top of 2018 data and remaining year as a
variable. The wide format is my final option that shows a better view.
Using the summary command, we know that the median value of
precipitation was 2.145(IQR 1.285-4.103) in 2017 and 5.455(IQR
4.190-8.182). The precipitation in 2017 is much higher than that in
2018. The distribution of precipitation data in both years are closer to
normal distrubuted than the sport ball data in trasj wheel if we compare
the difference of meidans and means.

In all my command, I check the integrity of data using some simple
commands as the check points. Meanwhile, these commands can help to
answer the questions regards data distribution.

# Problem 2

``` r
##upload and clean data in pols-month.csv
pols_month_dataset = read_csv(file = "./data/pols-month.csv") %>%   ##upload pols-month.csv
  janitor::clean_names() %>% ##clean the dataset
  separate(col = "mon", 
           sep = "-", 
           into = c("year", "month", "day"), 
           convert = type.convert("month", "year", "day" , 
                                  numerals = c("allow.loss"))) %>%  
           ##separate to year, month, day, and transfer month format "01" "02"... to "1", "2)
  transform(month = month.abb[month]) %>%       ##replace month number with month name
  mutate(president = case_when(
    prez_dem == 1 ~ "dem",
    prez_gop == 1 ~ "gop",
    TRUE ~ ""
  )) %>%  ##add variable president with value "dem" and "gop"
  select("year", "month", "gov_gop":"rep_gop", "gov_dem":"rep_dem", "president") 
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
   ##remove prez_gop, prez_dem and day variable

####checkpoints####
count(pols_month_dataset) # 822 observations #
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   822

``` r
head(pols_month_dataset,20)
```

    ##    year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ## 1  1947   Jan      23      51     253      23      45     198       dem
    ## 2  1947   Feb      23      51     253      23      45     198       dem
    ## 3  1947   Mar      23      51     253      23      45     198       dem
    ## 4  1947   Apr      23      51     253      23      45     198       dem
    ## 5  1947   May      23      51     253      23      45     198       dem
    ## 6  1947   Jun      23      51     253      23      45     198       dem
    ## 7  1947   Jul      23      51     253      23      45     198       dem
    ## 8  1947   Aug      23      51     253      23      45     198       dem
    ## 9  1947   Sep      23      51     253      23      45     198       dem
    ## 10 1947   Oct      23      51     253      23      45     198       dem
    ## 11 1947   Nov      24      51     253      23      45     198       dem
    ## 12 1947   Dec      24      51     253      23      45     198       dem
    ## 13 1948   Jan      22      53     253      24      48     198       dem
    ## 14 1948   Feb      22      53     253      24      48     198       dem
    ## 15 1948   Mar      22      53     253      24      48     198       dem
    ## 16 1948   Apr      22      53     253      24      48     198       dem
    ## 17 1948   May      22      53     253      24      48     198       dem
    ## 18 1948   Jun      22      53     253      24      48     198       dem
    ## 19 1948   Jul      22      53     253      24      48     198       dem
    ## 20 1948   Aug      22      53     253      24      48     198       dem

``` r
summary(pols_month_dataset)
```

    ##       year         month              gov_gop         sen_gop    
    ##  Min.   :1947   Length:822         Min.   :12.00   Min.   :32.0  
    ##  1st Qu.:1964   Class :character   1st Qu.:18.00   1st Qu.:42.0  
    ##  Median :1981   Mode  :character   Median :22.00   Median :46.0  
    ##  Mean   :1981                      Mean   :22.48   Mean   :46.1  
    ##  3rd Qu.:1998                      3rd Qu.:28.00   3rd Qu.:51.0  
    ##  Max.   :2015                      Max.   :34.00   Max.   :56.0  
    ##     rep_gop         gov_dem        sen_dem         rep_dem   
    ##  Min.   :141.0   Min.   :17.0   Min.   :44.00   Min.   :188  
    ##  1st Qu.:176.0   1st Qu.:22.0   1st Qu.:48.00   1st Qu.:211  
    ##  Median :195.0   Median :28.0   Median :53.00   Median :250  
    ##  Mean   :194.9   Mean   :27.2   Mean   :54.41   Mean   :245  
    ##  3rd Qu.:222.0   3rd Qu.:32.0   3rd Qu.:58.00   3rd Qu.:268  
    ##  Max.   :253.0   Max.   :41.0   Max.   :71.00   Max.   :301  
    ##   president        
    ##  Length:822        
    ##  Class :character  
    ##  Mode  :character  
    ##                    
    ##                    
    ## 

``` r
sum(is.na(close))
```

    ## Warning in is.na(close): is.na() applied to non-(list or vector) of type
    ## 'closure'

    ## [1] 0

``` r
####checkend####
```

``` r
##upload and clean data in snp.csv
snp_dataset = read_csv(file = "./data/snp.csv") %>% ##upload the data
  janitor::clean_names() %>%                         ##clean the data
  separate(col = "date", 
           sep = "/", 
           into = c("month", "day", "year"), 
           convert = type.convert("month", "day", "year", 
                                  numerals = c("allow.loss"))) %>% 
  transform(month = month.abb[month]) %>%            ##separate the data
  select("year", "month", "day", everything())       ##arrange the data
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
####checkpoints####
count(snp_dataset) # 787 observations #
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   787

``` r
head(snp_dataset,20)
```

    ##    year month day   close
    ## 1  2015   Jul   1 2079.65
    ## 2  2015   Jun   1 2063.11
    ## 3  2015   May   1 2107.39
    ## 4  2015   Apr   1 2085.51
    ## 5  2015   Mar   2 2067.89
    ## 6  2015   Feb   2 2104.50
    ## 7  2015   Jan   2 1994.99
    ## 8  2014   Dec   1 2058.90
    ## 9  2014   Nov   3 2067.56
    ## 10 2014   Oct   1 2018.05
    ## 11 2014   Sep   2 1972.29
    ## 12 2014   Aug   1 2003.37
    ## 13 2014   Jul   1 1930.67
    ## 14 2014   Jun   2 1960.23
    ## 15 2014   May   1 1923.57
    ## 16 2014   Apr   1 1883.95
    ## 17 2014   Mar   3 1872.34
    ## 18 2014   Feb   3 1859.45
    ## 19 2014   Jan   2 1782.59
    ## 20 2013   Dec   2 1848.36

``` r
summary(snp_dataset)
```

    ##       year         month                day            close        
    ##  Min.   :1950   Length:787         Min.   :1.000   Min.   :  17.05  
    ##  1st Qu.:1966   Class :character   1st Qu.:1.000   1st Qu.:  83.73  
    ##  Median :1982   Mode  :character   Median :1.000   Median : 138.53  
    ##  Mean   :1982                      Mean   :1.574   Mean   : 474.89  
    ##  3rd Qu.:1999                      3rd Qu.:2.000   3rd Qu.: 941.79  
    ##  Max.   :2015                      Max.   :4.000   Max.   :2107.39

``` r
sum(is.na(close))
```

    ## Warning in is.na(close): is.na() applied to non-(list or vector) of type
    ## 'closure'

    ## [1] 0

``` r
####checkend####
```

``` r
##upload and clean unemployment data
unemployment_dataset = read_csv(file = "./data/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment"
  ) %>% 
  janitor::clean_names()          ##clean the data
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
####checkpoints####
count(unemployment_dataset) # 816 observations #
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   816

``` r
head(unemployment_dataset,20)
```

    ## # A tibble: 20 x 3
    ##     year month unemployment
    ##    <dbl> <chr>        <dbl>
    ##  1  1948 Jan            3.4
    ##  2  1948 Feb            3.8
    ##  3  1948 Mar            4  
    ##  4  1948 Apr            3.9
    ##  5  1948 May            3.5
    ##  6  1948 Jun            3.6
    ##  7  1948 Jul            3.6
    ##  8  1948 Aug            3.9
    ##  9  1948 Sep            3.8
    ## 10  1948 Oct            3.7
    ## 11  1948 Nov            3.8
    ## 12  1948 Dec            4  
    ## 13  1949 Jan            4.3
    ## 14  1949 Feb            4.7
    ## 15  1949 Mar            5  
    ## 16  1949 Apr            5.3
    ## 17  1949 May            6.1
    ## 18  1949 Jun            6.2
    ## 19  1949 Jul            6.7
    ## 20  1949 Aug            6.8

``` r
summary(unemployment_dataset)
```

    ##       year         month            unemployment  
    ##  Min.   :1948   Length:816         Min.   : 2.50  
    ##  1st Qu.:1965   Class :character   1st Qu.: 4.70  
    ##  Median :1982   Mode  :character   Median : 5.60  
    ##  Mean   :1982                      Mean   : 5.83  
    ##  3rd Qu.:1998                      3rd Qu.: 6.90  
    ##  Max.   :2015                      Max.   :10.80  
    ##                                    NA's   :6

``` r
sum(is.na(unemployment_dataset$unemployment)) 
```

    ## [1] 6

``` r
# 6 missing value of unemployment in year 2015 from July to December#
####checkend####
```

``` r
## first merge the snp and pols dataset
merg_snp_pols_unem_dataset = full_join(snp_dataset, 
                                  pols_month_dataset, 
                                  by = c("year", "month")) %>% 
  left_join(unemployment_dataset, by = c("year", "month"))   ## then merge pols, snp and unemployment data

####checkpoints####
count(merg_snp_pols_unem_dataset) # 823 observations #
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   823

``` r
head(merg_snp_pols_unem_dataset,20)
```

    ##    year month day   close gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem
    ## 1  2015   Jul   1 2079.65      NA      NA      NA      NA      NA      NA
    ## 2  2015   Jun   1 2063.11      31      54     246      18      44     188
    ## 3  2015   May   1 2107.39      31      54     245      18      44     188
    ## 4  2015   Apr   1 2085.51      31      54     244      18      44     188
    ## 5  2015   Mar   2 2067.89      31      54     245      18      44     188
    ## 6  2015   Feb   2 2104.50      31      54     245      18      44     188
    ## 7  2015   Jan   2 1994.99      31      54     245      18      44     188
    ## 8  2014   Dec   1 2058.90      29      45     235      21      53     201
    ## 9  2014   Nov   3 2067.56      29      45     235      21      53     201
    ## 10 2014   Oct   1 2018.05      29      45     234      21      53     199
    ## 11 2014   Sep   2 1972.29      29      45     234      21      53     199
    ## 12 2014   Aug   1 2003.37      29      45     234      21      53     199
    ## 13 2014   Jul   1 1930.67      29      45     234      21      53     199
    ## 14 2014   Jun   2 1960.23      29      45     233      21      53     199
    ## 15 2014   May   1 1923.57      29      45     233      21      53     199
    ## 16 2014   Apr   1 1883.95      29      45     233      21      53     199
    ## 17 2014   Mar   3 1872.34      29      45     233      21      53     199
    ## 18 2014   Feb   3 1859.45      29      45     232      21      53     200
    ## 19 2014   Jan   2 1782.59      29      45     232      21      53     200
    ## 20 2013   Dec   2 1848.36      30      46     234      20      54     201
    ##    president unemployment
    ## 1       <NA>           NA
    ## 2        dem          5.3
    ## 3        dem          5.5
    ## 4        dem          5.4
    ## 5        dem          5.5
    ## 6        dem          5.5
    ## 7        dem          5.7
    ## 8        dem          5.6
    ## 9        dem          5.8
    ## 10       dem          5.7
    ## 11       dem          5.9
    ## 12       dem          6.1
    ## 13       dem          6.2
    ## 14       dem          6.1
    ## 15       dem          6.3
    ## 16       dem          6.2
    ## 17       dem          6.6
    ## 18       dem          6.7
    ## 19       dem          6.6
    ## 20       dem          6.7

``` r
summary(merg_snp_pols_unem_dataset)
```

    ##       year         month                day            close        
    ##  Min.   :1947   Length:823         Min.   :1.000   Min.   :  17.05  
    ##  1st Qu.:1964   Class :character   1st Qu.:1.000   1st Qu.:  83.73  
    ##  Median :1981   Mode  :character   Median :1.000   Median : 138.53  
    ##  Mean   :1981                      Mean   :1.574   Mean   : 474.89  
    ##  3rd Qu.:1998                      3rd Qu.:2.000   3rd Qu.: 941.79  
    ##  Max.   :2015                      Max.   :4.000   Max.   :2107.39  
    ##                                    NA's   :36      NA's   :36       
    ##     gov_gop         sen_gop        rep_gop         gov_dem    
    ##  Min.   :12.00   Min.   :32.0   Min.   :141.0   Min.   :17.0  
    ##  1st Qu.:18.00   1st Qu.:42.0   1st Qu.:176.0   1st Qu.:22.0  
    ##  Median :22.00   Median :46.0   Median :195.0   Median :28.0  
    ##  Mean   :22.48   Mean   :46.1   Mean   :194.9   Mean   :27.2  
    ##  3rd Qu.:28.00   3rd Qu.:51.0   3rd Qu.:222.0   3rd Qu.:32.0  
    ##  Max.   :34.00   Max.   :56.0   Max.   :253.0   Max.   :41.0  
    ##  NA's   :1       NA's   :1      NA's   :1       NA's   :1     
    ##     sen_dem         rep_dem     president          unemployment  
    ##  Min.   :44.00   Min.   :188   Length:823         Min.   : 2.50  
    ##  1st Qu.:48.00   1st Qu.:211   Class :character   1st Qu.: 4.70  
    ##  Median :53.00   Median :250   Mode  :character   Median : 5.60  
    ##  Mean   :54.41   Mean   :245                      Mean   : 5.83  
    ##  3rd Qu.:58.00   3rd Qu.:268                      3rd Qu.: 6.90  
    ##  Max.   :71.00   Max.   :301                      Max.   :10.80  
    ##  NA's   :1       NA's   :1                        NA's   :13

``` r
sum(is.na(merg_snp_pols_unem_dataset$unemployment)) #missing data 13#
```

    ## [1] 13

``` r
####checkend####
```

In problem2, we look at three datasets and link all of them togethere.
The poll dataset has 822 observarions from year 1947 to 2015, including
poll date (year, month, day), monthly number of governors,
senates,representatives, and presidents from the party of republic or
democratic with variable names of gov-pop, sen\_gop, rep\_gop,gov\_dem,
sen\_dem, rep\_dem, and president. As per question2 requirement, we
create a new varaible “president” as character variable to indicate the
party of the president: democratic or republic.

The dataset “snp” has 787 observations and 2 variables, indicating the
closing values of the S\&P index in each corresponding date. The median
value of closing S\&P is 138.58 (IQR:83.73-941.79). The mean is 474.89.
Since the mean value of S\&P is far greater than median, the S\&P is
right skewed.

The dataset “unemployment” has 816 observations and 2 variables,
indicating unemployment rate in each month from year 1948 to 2015. The
median unemployment rate was 5.6% (IQR: 4.7-6.9%). The highest rate was
10.8% and the lowest was 2.5%. In year 2015 from JUly to December, the
unemployment data was missing.

We, then, link all three individual datase togehter in two steps using
pipeline to simplify the command process. The final database include all
the information described above from each individual dataset – year,
month, day, S\&P closing value, gov\_gop, gov-pop, sen\_gop,
rep\_gop,gov\_dem, sen\_dem, rep\_dem, president, and unemployment rate.
We can use this database to examine the association beween poll data and
S\&P or unemployment, and the assocaition between S\&P and unemployment.
It is a very interesting dataset.

# Problem 3

``` r
#upload and clean the data
popular_baby_name_dataset = read_csv(file = "./data/Popular_Baby_Names.csv") %>% 
  janitor::clean_names() %>% 
  distinct()
```

    ## Parsed with column specification:
    ## cols(
    ##   `Year of Birth` = col_double(),
    ##   Gender = col_character(),
    ##   Ethnicity = col_character(),
    ##   `Child's First Name` = col_character(),
    ##   Count = col_double(),
    ##   Rank = col_double()
    ## )

``` r
####checkpoints####
count(popular_baby_name_dataset) # 19418 before distinct; 12181 after removing duplicates #
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1 12181

``` r
head(popular_baby_name_dataset,20)
```

    ## # A tibble: 20 x 6
    ##    year_of_birth gender ethnicity              childs_first_na~ count  rank
    ##            <dbl> <chr>  <chr>                  <chr>            <dbl> <dbl>
    ##  1          2016 FEMALE ASIAN AND PACIFIC ISL~ Olivia             172     1
    ##  2          2016 FEMALE ASIAN AND PACIFIC ISL~ Chloe              112     2
    ##  3          2016 FEMALE ASIAN AND PACIFIC ISL~ Sophia             104     3
    ##  4          2016 FEMALE ASIAN AND PACIFIC ISL~ Emily               99     4
    ##  5          2016 FEMALE ASIAN AND PACIFIC ISL~ Emma                99     4
    ##  6          2016 FEMALE ASIAN AND PACIFIC ISL~ Mia                 79     5
    ##  7          2016 FEMALE ASIAN AND PACIFIC ISL~ Charlotte           59     6
    ##  8          2016 FEMALE ASIAN AND PACIFIC ISL~ Sarah               57     7
    ##  9          2016 FEMALE ASIAN AND PACIFIC ISL~ Isabella            56     8
    ## 10          2016 FEMALE ASIAN AND PACIFIC ISL~ Hannah              56     8
    ## 11          2016 FEMALE ASIAN AND PACIFIC ISL~ Grace               54     9
    ## 12          2016 FEMALE ASIAN AND PACIFIC ISL~ Angela              54     9
    ## 13          2016 FEMALE ASIAN AND PACIFIC ISL~ Ava                 53    10
    ## 14          2016 FEMALE ASIAN AND PACIFIC ISL~ Joanna              49    11
    ## 15          2016 FEMALE ASIAN AND PACIFIC ISL~ Amelia              44    12
    ## 16          2016 FEMALE ASIAN AND PACIFIC ISL~ Evelyn              42    13
    ## 17          2016 FEMALE ASIAN AND PACIFIC ISL~ Ella                42    13
    ## 18          2016 FEMALE ASIAN AND PACIFIC ISL~ Arya                42    13
    ## 19          2016 FEMALE ASIAN AND PACIFIC ISL~ Ariana              40    14
    ## 20          2016 FEMALE ASIAN AND PACIFIC ISL~ Maya                39    15

``` r
summary(popular_baby_name_dataset)
```

    ##  year_of_birth     gender           ethnicity         childs_first_name 
    ##  Min.   :2011   Length:12181       Length:12181       Length:12181      
    ##  1st Qu.:2012   Class :character   Class :character   Class :character  
    ##  Median :2014   Mode  :character   Mode  :character   Mode  :character  
    ##  Mean   :2014                                                           
    ##  3rd Qu.:2015                                                           
    ##  Max.   :2016                                                           
    ##      count             rank       
    ##  Min.   : 10.00   Min.   :  1.00  
    ##  1st Qu.: 13.00   1st Qu.: 38.00  
    ##  Median : 20.00   Median : 59.00  
    ##  Mean   : 34.21   Mean   : 57.13  
    ##  3rd Qu.: 36.00   3rd Qu.: 78.00  
    ##  Max.   :426.00   Max.   :102.00

``` r
####checkend####

##filter the male baby with "white non hispanic" and "2016"
popular_male_baby_name_dataset = popular_baby_name_dataset %>% 
  filter(gender == "MALE") %>% 
  filter(ethnicity == "WHITE NON HISPANIC") %>% 
  filter(year_of_birth == 2016)

####checkpoints####
count(popular_male_baby_name_dataset) # 364 obs #
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   364

``` r
head(popular_male_baby_name_dataset,20)
```

    ## # A tibble: 20 x 6
    ##    year_of_birth gender ethnicity          childs_first_name count  rank
    ##            <dbl> <chr>  <chr>              <chr>             <dbl> <dbl>
    ##  1          2016 MALE   WHITE NON HISPANIC Joseph              261     1
    ##  2          2016 MALE   WHITE NON HISPANIC Michael             260     2
    ##  3          2016 MALE   WHITE NON HISPANIC David               255     3
    ##  4          2016 MALE   WHITE NON HISPANIC Moshe               239     4
    ##  5          2016 MALE   WHITE NON HISPANIC Jacob               236     5
    ##  6          2016 MALE   WHITE NON HISPANIC James               231     6
    ##  7          2016 MALE   WHITE NON HISPANIC Benjamin            219     7
    ##  8          2016 MALE   WHITE NON HISPANIC Alexander           211     8
    ##  9          2016 MALE   WHITE NON HISPANIC Daniel              196     9
    ## 10          2016 MALE   WHITE NON HISPANIC Henry               196     9
    ## 11          2016 MALE   WHITE NON HISPANIC Adam                178    10
    ## 12          2016 MALE   WHITE NON HISPANIC Jack                178    10
    ## 13          2016 MALE   WHITE NON HISPANIC William             169    11
    ## 14          2016 MALE   WHITE NON HISPANIC Abraham             163    12
    ## 15          2016 MALE   WHITE NON HISPANIC Samuel              156    13
    ## 16          2016 MALE   WHITE NON HISPANIC Noah                147    14
    ## 17          2016 MALE   WHITE NON HISPANIC John                146    15
    ## 18          2016 MALE   WHITE NON HISPANIC Isaac               143    16
    ## 19          2016 MALE   WHITE NON HISPANIC Oliver              142    17
    ## 20          2016 MALE   WHITE NON HISPANIC Chaim               140    18

``` r
summary(popular_male_baby_name_dataset)
```

    ##  year_of_birth     gender           ethnicity         childs_first_name 
    ##  Min.   :2016   Length:364         Length:364         Length:364        
    ##  1st Qu.:2016   Class :character   Class :character   Class :character  
    ##  Median :2016   Mode  :character   Mode  :character   Mode  :character  
    ##  Mean   :2016                                                           
    ##  3rd Qu.:2016                                                           
    ##  Max.   :2016                                                           
    ##      count             rank      
    ##  Min.   : 10.00   Min.   : 1.00  
    ##  1st Qu.: 14.00   1st Qu.:67.00  
    ##  Median : 24.00   Median :85.00  
    ##  Mean   : 40.66   Mean   :76.18  
    ##  3rd Qu.: 43.00   3rd Qu.:95.00  
    ##  Max.   :261.00   Max.   :99.00

``` r
####checkend####


##produce a scatter plot showing the number of children with a name (y axis) against the rank in popularity of that name (x axis)
plot(popular_male_baby_name_dataset$rank, popular_male_baby_name_dataset$count,
     xlab = "the number of white non-Hispanic boys with a name",
     ylab = "the rank in popularity of that name")
```

![](p8105_hw2_yh2736_files/figure-gfm/babyname-1.png)<!-- -->

This is a very interesting dataset to educate myself on the popular
names in America, adding new information to my knowldege pool\! The
final scatter plot shows among white non-Hispanic boys, the number of
names (100) increases while the higher ranking (1). Although I have
answered the study question, I am not very happy with this scatter plot.
In my real project, I may want to show a plot with positive slope by
inversing the y-axis.

Great practices for homework 2. I really enjoy it\!
